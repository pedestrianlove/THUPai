name: update data and deploy

on:
  schedule:
    - cron: "0 8 * * *"
  push:
    branches:
      - 'main'

jobs:
  update-data-and-build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: corepack enable
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: "Install crawler's dependencies"
        run: |
          pip install Scrapy
      
      - name: "Execute the crawler"
        working-directory: ./crawler
        run: |
          scrapy crawl courses
    
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      - name: Build nuxt
        run: |
          npm install
          NUXT_APP_BASE_URL=/${{ github.event.repository.name }}/ npx nuxt build --preset github_pages

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./.output/public

  deploy:
    # Add a dependency to the build job
    needs: update-data-and-build
    # Grant GITHUB_TOKEN the permissions required to make a Pages deployment
    permissions:
      pages: write      # to deploy to Pages
      id-token: write   # to verify the deployment originates from an appropriate source
    # Deploy to the github_pages environment
    environment:
      name: github_pages
      url: ${{ steps.deployment.outputs.page_url }}
    # Specify runner + deployment step
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
